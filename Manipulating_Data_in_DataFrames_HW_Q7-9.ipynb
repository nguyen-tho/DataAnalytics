{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create our own dataset to work with real dates\n",
    "\n",
    "This is a dataset of patient visits from a medical office. It contains the patients first and last names, date of birth, and the dates of their first 3 visits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+----------+----------+----------+\n",
      "|first_name|last_name|       dob|    visit1|    visit2|    visit3|\n",
      "+----------+---------+----------+----------+----------+----------+\n",
      "|  Mohammed|   Alfasy|1987-04-08|2016-01-07|2017-02-03|2018-03-02|\n",
      "|     Marcy|Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|\n",
      "|     Ginny|   Ginger|1986-07-10|2014-08-07|2015-02-03|2016-03-02|\n",
      "|     Vijay| Doberson|1988-05-02|2016-01-07|2018-02-03|2018-03-02|\n",
      "|     Orhan|  Gelicek|1987-05-11|2016-05-07|2017-01-03|2018-09-02|\n",
      "|     Sarah|    Jones|1956-07-06|2016-04-07|2017-08-03|2018-10-02|\n",
      "|      John|  Johnson|2017-10-12|2018-01-02|2018-10-03|2018-03-02|\n",
      "+----------+---------+----------+----------+----------+----------+\n",
      "\n",
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- visit1: date (nullable = true)\n",
      " |-- visit2: date (nullable = true)\n",
      " |-- visit3: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType\n",
    "from pyspark.sql.functions import to_date, expr\n",
    "\n",
    "# Tạo phiên Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Date Conversion\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu\n",
    "md_office = [\n",
    "    ('Mohammed', 'Alfasy', '1987-04-08', '2016-01-07', '2017-02-03', '2018-03-02'),\n",
    "    ('Marcy', 'Wellmaker', '1986-04-08', '2015-01-07', '2017-01-03', '2018-01-02'),\n",
    "    ('Ginny', 'Ginger', '1986-07-10', '2014-08-07', '2015-02-03', '2016-03-02'),\n",
    "    ('Vijay', 'Doberson', '1988-05-02', '2016-01-07', '2018-02-03', '2018-03-02'),\n",
    "    ('Orhan', 'Gelicek', '1987-05-11', '2016-05-07', '2017-01-03', '2018-09-02'),\n",
    "    ('Sarah', 'Jones', '1956-07-06', '2016-04-07', '2017-08-03', '2018-10-02'),\n",
    "    ('John', 'Johnson', '2017-10-12', '2018-01-02', '2018-10-03', '2018-03-02')\n",
    "]\n",
    "\n",
    "# Định nghĩa schema cho DataFrame\n",
    "schema = StructType([\n",
    "    StructField('first_name', StringType(), True),\n",
    "    StructField('last_name', StringType(), True),\n",
    "    StructField('dob', StringType(), True),\n",
    "    StructField('visit1', StringType(), True),\n",
    "    StructField('visit2', StringType(), True),\n",
    "    StructField('visit3', StringType(), True)\n",
    "])\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu và schema\n",
    "df = spark.createDataFrame(md_office, schema)\n",
    "\n",
    "# Chuyển đổi chuỗi ngày tháng thành ngày tháng với chế độ \"LEGACY\"\n",
    "df = df.withColumn('dob', to_date(expr(\"lpad(dob, 10, '0')\"), 'yyyy-MM-dd')) \\\n",
    "       .withColumn('visit1', to_date(expr(\"lpad(visit1, 10, '0')\"), 'yyyy-MM-dd')) \\\n",
    "       .withColumn('visit2', to_date(expr(\"lpad(visit2, 10, '0')\"), 'yyyy-MM-dd')) \\\n",
    "       .withColumn('visit3', to_date(expr(\"lpad(visit3, 10, '0')\"), 'yyyy-MM-dd'))\n",
    "\n",
    "# Hiển thị DataFrame và schema\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Can you calculate a variable showing the length of time between patient visits?\n",
    "\n",
    "Compare visit1 to visit2 and visit2 to visit3 for all patients and see what the average length of time is between visits. Create an alias for it as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+\n",
      "|(avg(visit1_to_visit2 AS avg_visit_interval12) + avg(visit2_to_visit3 AS avg_visit_interval23))|\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "|                                                                              721.2857142857142|\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, datediff, avg\n",
    "\n",
    "# Calculate the difference between visit dates (in days)\n",
    "df = df.withColumn(\"visit1_to_visit2\", datediff(col(\"visit2\"), col(\"visit1\"))) \\\n",
    "       .withColumn(\"visit2_to_visit3\", datediff(col(\"visit3\"), col(\"visit2\")))\n",
    "\n",
    "# Calculate the average time between visits (in days)\n",
    "avg_visit_interval = df.select(avg(col(\"visit1_to_visit2\").alias(\"avg_visit_interval12\")) + \\\n",
    "                              avg(col(\"visit2_to_visit3\").alias(\"avg_visit_interval23\")))\n",
    "\n",
    "# Print the results\n",
    "avg_visit_interval.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Can you calculate the age of each patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+------------------+\n",
      "|first_name|last_name|       dob|    visit1|    visit2|    visit3|visit1_to_visit2|visit2_to_visit3|               age|\n",
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+------------------+\n",
      "|  Mohammed|   Alfasy|1987-04-08|2016-01-07|2017-02-03|2018-03-02|             393|             392| 36.90075290896646|\n",
      "|     Marcy|Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|             727|             364| 37.90006844626968|\n",
      "|     Ginny|   Ginger|1986-07-10|2014-08-07|2015-02-03|2016-03-02|             180|             393| 37.64544832306639|\n",
      "|     Vijay| Doberson|1988-05-02|2016-01-07|2018-02-03|2018-03-02|             758|              27|35.832991101984945|\n",
      "|     Orhan|  Gelicek|1987-05-11|2016-05-07|2017-01-03|2018-09-02|             241|             607|  36.8104038329911|\n",
      "|     Sarah|    Jones|1956-07-06|2016-04-07|2017-08-03|2018-10-02|             483|             425| 67.65503080082135|\n",
      "|      John|  Johnson|2017-10-12|2018-01-02|2018-10-03|2018-03-02|             274|            -215|6.3874058863791925|\n",
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, current_date\n",
    "age = df.withColumn('age', (datediff(current_date(), col(\"dob\"))/365.25)) # based on Gregorian calendar, we have 365 days and appox 4 hours per year\n",
    "age.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Can you extract the month from the first visit column and call it \"Month\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+-----+\n",
      "|first_name|last_name|       dob|    visit1|    visit2|    visit3|visit1_to_visit2|visit2_to_visit3|Month|\n",
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+-----+\n",
      "|  Mohammed|   Alfasy|1987-04-08|2016-01-07|2017-02-03|2018-03-02|             393|             392|    1|\n",
      "|     Marcy|Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|             727|             364|    1|\n",
      "|     Ginny|   Ginger|1986-07-10|2014-08-07|2015-02-03|2016-03-02|             180|             393|    8|\n",
      "|     Vijay| Doberson|1988-05-02|2016-01-07|2018-02-03|2018-03-02|             758|              27|    1|\n",
      "|     Orhan|  Gelicek|1987-05-11|2016-05-07|2017-01-03|2018-09-02|             241|             607|    5|\n",
      "|     Sarah|    Jones|1956-07-06|2016-04-07|2017-08-03|2018-10-02|             483|             425|    4|\n",
      "|      John|  Johnson|2017-10-12|2018-01-02|2018-10-03|2018-03-02|             274|            -215|    1|\n",
      "+----------+---------+----------+----------+----------+----------+----------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, month\n",
    "\n",
    "# Extract month from the \"visit1\" column and name it \"Month\"\n",
    "df = df.withColumn(\"Month\", month(col(\"visit1\")).alias(\"Month\"))\n",
    "\n",
    "# Print the DataFrame with the new column\n",
    "df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
