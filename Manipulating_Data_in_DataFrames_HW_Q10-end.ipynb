{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Challenges with working with date and timestamps\n",
    "\n",
    "Let's read in the supermarket sales dataframe attached to the lecture now and see some of the issues that can come up when working with date and timestamps values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def create_spark(appname):\n",
    "    \"\"\"Create a SparkSession as 'spark'\n",
    "    Returns:\n",
    "        SparkSession : A Spark Session that can\n",
    "        be used to perform spark operations.\n",
    "        \"\"\"\n",
    "    spark = SparkSession.builder.appName(appname).config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\").getOrCreate()\n",
    "    return spark\n",
    "\n",
    "dataset_path = 'dataset\\supermarket_sales - Sheet1.csv'\n",
    "spark = create_spark('supermarketSale')\n",
    "\n",
    "sales = spark.read.csv(dataset_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this dataset\n",
    "\n",
    "The growth of supermarkets in most populated cities are increasing and market competitions are also high. The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data. \n",
    "\n",
    " - Attribute information\n",
    " - Invoice id: Computer generated sales slip invoice identification number\n",
    " - Branch: Branch of supercenter (3 branches are available identified by A, B and C).\n",
    " - City: Location of supercenters\n",
    " - Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.\n",
    " - Gender: Gender type of customer\n",
    " - Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel\n",
    " - Unit price: Price of each product in USD\n",
    " - Quantity: Number of products purchased by customer\n",
    " - Tax: 5% tax fee for customer buying\n",
    " - Total: Total price including tax\n",
    " - Date: Date of purchase (Record available from January 2019 to March 2019)\n",
    " - Time: Purchase time (10am to 9pm)\n",
    " - Payment: Payment used by customer for purchase (3 methods are available â€“ Cash, Credit card and Ewallet)\n",
    " - COGS: Cost of goods sold\n",
    " - Gross margin percentage: Gross margin percentage\n",
    " - Gross income: Gross income\n",
    " - Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10)\n",
    "\n",
    "**Source:** https://www.kaggle.com/aungpyaeap/supermarket-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View dataframe and schema as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "| Invoice ID|Branch|     City|Customer type|Gender|        Product line|Unit price|Quantity| Tax 5%|   Total|     Date| Time|    Payment|  cogs|gross margin percentage|gross income|Rating|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "|750-67-8428|     A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|548.9715| 1/5/2019|13:08|    Ewallet|522.83|            4.761904762|     26.1415|   9.1|\n",
      "|226-31-3081|     C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|   80.22| 3/8/2019|10:29|       Cash|  76.4|            4.761904762|        3.82|   9.6|\n",
      "|631-41-3108|     A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|340.5255| 3/3/2019|13:23|Credit card|324.31|            4.761904762|     16.2155|   7.4|\n",
      "|123-19-1176|     A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 489.048|1/27/2019|20:33|    Ewallet|465.76|            4.761904762|      23.288|   8.4|\n",
      "|373-73-7910|     A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|634.3785| 2/8/2019|10:37|    Ewallet|604.17|            4.761904762|     30.2085|   5.3|\n",
      "|699-14-3026|     C|Naypyitaw|       Normal|  Male|Electronic access...|     85.39|       7|29.8865|627.6165|3/25/2019|18:30|    Ewallet|597.73|            4.761904762|     29.8865|   4.1|\n",
      "|355-53-5943|     A|   Yangon|       Member|Female|Electronic access...|     68.84|       6| 20.652| 433.692|2/25/2019|14:36|    Ewallet|413.04|            4.761904762|      20.652|   5.8|\n",
      "|315-22-5665|     C|Naypyitaw|       Normal|Female|  Home and lifestyle|     73.56|      10|  36.78|  772.38|2/24/2019|11:38|    Ewallet| 735.6|            4.761904762|       36.78|     8|\n",
      "|665-32-9167|     A|   Yangon|       Member|Female|   Health and beauty|     36.26|       2|  3.626|  76.146|1/10/2019|17:15|Credit card| 72.52|            4.761904762|       3.626|   7.2|\n",
      "|692-92-5582|     B| Mandalay|       Member|Female|  Food and beverages|     54.84|       3|  8.226| 172.746|2/20/2019|13:27|Credit card|164.52|            4.761904762|       8.226|   5.9|\n",
      "|351-62-0822|     B| Mandalay|       Member|Female| Fashion accessories|     14.48|       4|  2.896|  60.816| 2/6/2019|18:07|    Ewallet| 57.92|            4.761904762|       2.896|   4.5|\n",
      "|529-56-3974|     B| Mandalay|       Member|  Male|Electronic access...|     25.51|       4|  5.102| 107.142| 3/9/2019|17:03|       Cash|102.04|            4.761904762|       5.102|   6.8|\n",
      "|365-64-0515|     A|   Yangon|       Normal|Female|Electronic access...|     46.95|       5|11.7375|246.4875|2/12/2019|10:25|    Ewallet|234.75|            4.761904762|     11.7375|   7.1|\n",
      "|252-56-2699|     A|   Yangon|       Normal|  Male|  Food and beverages|     43.19|      10| 21.595| 453.495| 2/7/2019|16:48|    Ewallet| 431.9|            4.761904762|      21.595|   8.2|\n",
      "|829-34-3910|     A|   Yangon|       Normal|Female|   Health and beauty|     71.38|      10|  35.69|  749.49|3/29/2019|19:21|       Cash| 713.8|            4.761904762|       35.69|   5.7|\n",
      "|299-46-1805|     B| Mandalay|       Member|Female|   Sports and travel|     93.72|       6| 28.116| 590.436|1/15/2019|16:19|       Cash|562.32|            4.761904762|      28.116|   4.5|\n",
      "|656-95-9349|     A|   Yangon|       Member|Female|   Health and beauty|     68.93|       7|24.1255|506.6355|3/11/2019|11:03|Credit card|482.51|            4.761904762|     24.1255|   4.6|\n",
      "|765-26-6951|     A|   Yangon|       Normal|  Male|   Sports and travel|     72.61|       6| 21.783| 457.443| 1/1/2019|10:39|Credit card|435.66|            4.761904762|      21.783|   6.9|\n",
      "|329-62-1586|     A|   Yangon|       Normal|  Male|  Food and beverages|     54.67|       3| 8.2005|172.2105|1/21/2019|18:00|Credit card|164.01|            4.761904762|      8.2005|   8.6|\n",
      "|319-50-3348|     B| Mandalay|       Normal|Female|  Home and lifestyle|      40.3|       2|   4.03|   84.63|3/11/2019|15:30|    Ewallet|  80.6|            4.761904762|        4.03|   4.4|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-----+-----------+------+-----------------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view data\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Branch: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Customer type: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Product line: string (nullable = true)\n",
      " |-- Unit price: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- Tax 5%: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Payment: string (nullable = true)\n",
      " |-- cogs: string (nullable = true)\n",
      " |-- gross margin percentage: string (nullable = true)\n",
      " |-- gross income: string (nullable = true)\n",
      " |-- Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view schema\n",
    "sales.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date field to date type\n",
    "\n",
    "Looks like we need to convert the date field into a date type. Let's go ahead and do that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, expr\n",
    "sales = sales.withColumn('Date', to_date(expr(\"lpad(Date, 10, '0')\"), 'MM/dd/yyyy'))\n",
    "#sales = sales.withColumn(\"Date\", to_date(col(\"Date\"), format=\"MM/dd/yyyy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we extract the month value from the date field?\n",
    "\n",
    "If you had trouble converting the date field in the previous question think about a more creative solution to extract the month from that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-----+-----------+------+-----------------------+------------+------+-----+\n",
      "| Invoice ID|Branch|     City|Customer type|Gender|        Product line|Unit price|Quantity| Tax 5%|   Total|      Date| Time|    Payment|  cogs|gross margin percentage|gross income|Rating|Month|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-----+-----------+------+-----------------------+------------+------+-----+\n",
      "|750-67-8428|     A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|548.9715|2019-01-05|13:08|    Ewallet|522.83|            4.761904762|     26.1415|   9.1|    1|\n",
      "|226-31-3081|     C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|   80.22|2019-03-08|10:29|       Cash|  76.4|            4.761904762|        3.82|   9.6|    3|\n",
      "|631-41-3108|     A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|340.5255|2019-03-03|13:23|Credit card|324.31|            4.761904762|     16.2155|   7.4|    3|\n",
      "|123-19-1176|     A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 489.048|2019-01-27|20:33|    Ewallet|465.76|            4.761904762|      23.288|   8.4|    1|\n",
      "|373-73-7910|     A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|634.3785|2019-02-08|10:37|    Ewallet|604.17|            4.761904762|     30.2085|   5.3|    2|\n",
      "|699-14-3026|     C|Naypyitaw|       Normal|  Male|Electronic access...|     85.39|       7|29.8865|627.6165|2019-03-25|18:30|    Ewallet|597.73|            4.761904762|     29.8865|   4.1|    3|\n",
      "|355-53-5943|     A|   Yangon|       Member|Female|Electronic access...|     68.84|       6| 20.652| 433.692|2019-02-25|14:36|    Ewallet|413.04|            4.761904762|      20.652|   5.8|    2|\n",
      "|315-22-5665|     C|Naypyitaw|       Normal|Female|  Home and lifestyle|     73.56|      10|  36.78|  772.38|2019-02-24|11:38|    Ewallet| 735.6|            4.761904762|       36.78|     8|    2|\n",
      "|665-32-9167|     A|   Yangon|       Member|Female|   Health and beauty|     36.26|       2|  3.626|  76.146|2019-01-10|17:15|Credit card| 72.52|            4.761904762|       3.626|   7.2|    1|\n",
      "|692-92-5582|     B| Mandalay|       Member|Female|  Food and beverages|     54.84|       3|  8.226| 172.746|2019-02-20|13:27|Credit card|164.52|            4.761904762|       8.226|   5.9|    2|\n",
      "|351-62-0822|     B| Mandalay|       Member|Female| Fashion accessories|     14.48|       4|  2.896|  60.816|2019-02-06|18:07|    Ewallet| 57.92|            4.761904762|       2.896|   4.5|    2|\n",
      "|529-56-3974|     B| Mandalay|       Member|  Male|Electronic access...|     25.51|       4|  5.102| 107.142|2019-03-09|17:03|       Cash|102.04|            4.761904762|       5.102|   6.8|    3|\n",
      "|365-64-0515|     A|   Yangon|       Normal|Female|Electronic access...|     46.95|       5|11.7375|246.4875|2019-02-12|10:25|    Ewallet|234.75|            4.761904762|     11.7375|   7.1|    2|\n",
      "|252-56-2699|     A|   Yangon|       Normal|  Male|  Food and beverages|     43.19|      10| 21.595| 453.495|2019-02-07|16:48|    Ewallet| 431.9|            4.761904762|      21.595|   8.2|    2|\n",
      "|829-34-3910|     A|   Yangon|       Normal|Female|   Health and beauty|     71.38|      10|  35.69|  749.49|2019-03-29|19:21|       Cash| 713.8|            4.761904762|       35.69|   5.7|    3|\n",
      "|299-46-1805|     B| Mandalay|       Member|Female|   Sports and travel|     93.72|       6| 28.116| 590.436|2019-01-15|16:19|       Cash|562.32|            4.761904762|      28.116|   4.5|    1|\n",
      "|656-95-9349|     A|   Yangon|       Member|Female|   Health and beauty|     68.93|       7|24.1255|506.6355|2019-03-11|11:03|Credit card|482.51|            4.761904762|     24.1255|   4.6|    3|\n",
      "|765-26-6951|     A|   Yangon|       Normal|  Male|   Sports and travel|     72.61|       6| 21.783| 457.443|2019-01-01|10:39|Credit card|435.66|            4.761904762|      21.783|   6.9|    1|\n",
      "|329-62-1586|     A|   Yangon|       Normal|  Male|  Food and beverages|     54.67|       3| 8.2005|172.2105|2019-01-21|18:00|Credit card|164.01|            4.761904762|      8.2005|   8.6|    1|\n",
      "|319-50-3348|     B| Mandalay|       Normal|Female|  Home and lifestyle|      40.3|       2|   4.03|   84.63|2019-03-11|15:30|    Ewallet|  80.6|            4.761904762|        4.03|   4.4|    3|\n",
      "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+----------+-----+-----------+------+-----------------------+------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month,col\n",
    "sales = sales.withColumn(\n",
    "    \"Month\", month(col(\"Date\")).alias(\"Month\")\n",
    ")\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.0 Working with Arrays\n",
    "\n",
    "Here is a dataframe of reviews from the movie the Dark Night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------------------------------------------------------------------------+\n",
      "|rating|review_txt                                                                            |\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "|5     |Epic. This is the best movie I have EVER seen                                         |\n",
      "|4     |Pretty good, but I would have liked to seen better special effects                    |\n",
      "|3     |So so. Casting could have been improved                                               |\n",
      "|5     |The most EPIC movie of the year! Casting was awesome. Special effects were so intense.|\n",
      "|4     |Solid but I would have liked to see more of the love story                            |\n",
      "|5     |THE BOMB!!!!!!!                                                                       |\n",
      "+------+--------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "values = [(5,'Epic. This is the best movie I have EVER seen'), \\\n",
    "          (4,'Pretty good, but I would have liked to seen better special effects'), \\\n",
    "          (3,'So so. Casting could have been improved'), \\\n",
    "          (5,'The most EPIC movie of the year! Casting was awesome. Special effects were so intense.'), \\\n",
    "          (4,'Solid but I would have liked to see more of the love story'), \\\n",
    "          (5,'THE BOMB!!!!!!!')]\n",
    "reviews = spark.createDataFrame(values,['rating', 'review_txt'])\n",
    "\n",
    "reviews.show(6,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Let's see if we can create an array off of the review text column and then derive some meaningful results from it.\n",
    "\n",
    "**But first** we need to clean the rview_txt column to make sure we can get what we need from our analysis later on. So let's do the following:\n",
    "\n",
    "1. Remove all punctuation\n",
    "2. lower case everything\n",
    "3. Remove white space (trim)\n",
    "3. Then finally, split the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|rating|original_review                                                                    |review_words                                                                                       |\n",
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|5     |epic this is the best movie i have ever seen                                       |[epic, this, is, the, best, movie, i, have, ever, seen]                                            |\n",
      "|4     |pretty good but i would have liked to seen better special effects                  |[pretty, good, but, i, would, have, liked, to, seen, better, special, effects]                     |\n",
      "|3     |so so casting could have been improved                                             |[so, so, casting, could, have, been, improved]                                                     |\n",
      "|5     |the most epic movie of the year casting was awesome special effects were so intense|[the, most, epic, movie, of, the, year, casting, was, awesome, special, effects, were, so, intense]|\n",
      "|4     |solid but i would have liked to see more of the love story                         |[solid, but, i, would, have, liked, to, see, more, of, the, love, story]                           |\n",
      "|5     |the bomb                                                                           |[the, bomb]                                                                                        |\n",
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, lower, trim, split\n",
    "\n",
    "def clean_review_text(df):\n",
    "  \"\"\"\n",
    "  Cleans the review_txt column by removing punctuation, converting to lowercase,\n",
    "  trimming whitespace, and splitting the string into words.\n",
    "\n",
    "  Args:\n",
    "    df: A Spark DataFrame with a column named 'review_txt'.\n",
    "\n",
    "  Returns:\n",
    "    A new Spark DataFrame with the cleaned 'review_txt' column named 'cleaned_review'.\n",
    "  \"\"\"\n",
    "\n",
    "  # Remove punctuation\n",
    "  df = df.withColumn(\"review_txt\", regexp_replace(col(\"review_txt\"), r\"[^\\w\\s]\", \"\"))\n",
    "\n",
    "  # Lowercase everything\n",
    "  df = df.withColumn(\"review_txt\", lower(col(\"review_txt\")))\n",
    "\n",
    "  # Trim whitespace\n",
    "  df = df.withColumn(\"review_txt\", trim(col(\"review_txt\")))\n",
    "\n",
    "  # Split the string into words\n",
    "  df = df.withColumn(\"cleaned_review\", split(col(\"review_txt\"), \" \"))\n",
    "\n",
    "  # Rename the cleaned column\n",
    "  df = df.withColumnRenamed(\"review_txt\", \"original_review\")\n",
    "  df = df.withColumnRenamed(\"cleaned_review\", \"review_words\")\n",
    "\n",
    "  return df\n",
    "\n",
    "# Apply the cleaning function\n",
    "cleaned_df = clean_review_text(reviews)\n",
    "\n",
    "# Show the cleaned DataFrame\n",
    "cleaned_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Alright now let's see if we can find which reviews contain the word 'Epic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|rating|original_review                                                                    |review_words                                                                                       |\n",
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "|5     |epic this is the best movie i have ever seen                                       |[epic, this, is, the, best, movie, i, have, ever, seen]                                            |\n",
      "|5     |the most epic movie of the year casting was awesome special effects were so intense|[the, most, epic, movie, of, the, year, casting, was, awesome, special, effects, were, so, intense]|\n",
      "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, array_contains\n",
    "\n",
    "# Filter reviews containing the word \"Epic\" (case-insensitive)\n",
    "epic_reviews = cleaned_df.filter(array_contains(col(\"review_words\"), \"epic\"))\n",
    "\n",
    "# Show the reviews containing \"Epic\"\n",
    "epic_reviews.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
