{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating DataFrames in PySpark HW\n",
    "\n",
    "First let's start up our PySpark instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('airbnb').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the dataFrame for this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/nyc_air_bnb.csv'\n",
    "airbnb = spark.read.csv(dataset_path,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this dataset\n",
    "\n",
    "This dataset describes the listing activity and metrics for Air BNB bookers in NYC, NY for 2019. Each line in the dataset is a booking. \n",
    "\n",
    "**Source:** https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data/data\n",
    "\n",
    "Let's go ahead and view the first few records of the dataset so we know what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------+-----------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|  id|                name|host_id|  host_name|neighbourhood_group|neighbourhood|latitude|longitude|      room_type|price|minimum_nights|number_of_reviews|last_review|reviews_per_month|calculated_host_listings_count|availability_365|\n",
      "+----+--------------------+-------+-----------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "|2539|Clean & quiet apt...|   2787|       John|           Brooklyn|   Kensington|40.64749|-73.97237|   Private room|  149|             1|                9| 2018-10-19|             0.21|                             6|             365|\n",
      "|2595|Skylit Midtown Ca...|   2845|   Jennifer|          Manhattan|      Midtown|40.75362|-73.98377|Entire home/apt|  225|             1|               45| 2019-05-21|             0.38|                             2|             355|\n",
      "|3647|THE VILLAGE OF HA...|   4632|  Elisabeth|          Manhattan|       Harlem|40.80902| -73.9419|   Private room|  150|             3|                0|       NULL|             NULL|                             1|             365|\n",
      "|3831|Cozy Entire Floor...|   4869|LisaRoxanne|           Brooklyn| Clinton Hill|40.68514|-73.95976|Entire home/apt|   89|             1|              270| 2019-07-05|             4.64|                             1|             194|\n",
      "|5022|Entire Apt: Spaci...|   7192|      Laura|          Manhattan|  East Harlem|40.79851|-73.94399|Entire home/apt|   80|            10|                9| 2018-11-19|             0.10|                             1|               0|\n",
      "+----+--------------------+-------+-----------+-------------------+-------------+--------+---------+---------------+-----+--------------+-----------------+-----------+-----------------+------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the schema so we can make sure all the variables have the correct types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- host_id: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: string (nullable = true)\n",
      " |-- number_of_reviews: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- reviews_per_month: string (nullable = true)\n",
      " |-- calculated_host_listings_count: string (nullable = true)\n",
      " |-- availability_365: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airbnb.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that some of the columns that are obviously numeric have been incorrectly identified as \"strings\". Let's edit that. Otherwise we cannot aggregate any of the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- last_review: date (nullable = true)\n",
      " |-- reviews_per_month: float (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import to_date\n",
    "def change_data_type(df, col, new_type):\n",
    "    return df.withColumn(col, df[col].cast(new_type))\n",
    "\n",
    "airbnb = change_data_type(airbnb, 'id',  'int')\n",
    "airbnb = change_data_type(airbnb, 'host_id', 'int')\n",
    "airbnb = change_data_type(airbnb, 'latitude', 'float')\n",
    "airbnb = change_data_type(airbnb,'longitude','float')\n",
    "airbnb = change_data_type(airbnb, 'price', 'int')\n",
    "airbnb = change_data_type(airbnb, 'minimum_nights', 'int')\n",
    "airbnb = change_data_type(airbnb, 'number_of_reviews', 'int')\n",
    "airbnb = change_data_type(airbnb,'reviews_per_month','float')\n",
    "airbnb = change_data_type(airbnb, 'calculated_host_listings_count', 'int')\n",
    "airbnb = change_data_type(airbnb, 'availability_365', 'int')\n",
    "airbnb = airbnb.withColumn('last_review', to_date(airbnb[\"last_review\"], format='MM/dd/yyyy'))\n",
    "airbnb.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright now we are ready to dig in!\n",
    "\n",
    "\n",
    "### 1. How many rows are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 49079\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows\n",
    "num_rows = airbnb.count()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of rows in the dataset: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How many total reviews does each host have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "| host_id|total_reviews|\n",
      "+--------+-------------+\n",
      "|  291112|            1|\n",
      "| 1384111|            2|\n",
      "| 1597481|            1|\n",
      "| 2108853|            1|\n",
      "| 2429432|            1|\n",
      "| 2530670|            1|\n",
      "| 3432742|            1|\n",
      "| 1360296|            1|\n",
      "| 2124690|            1|\n",
      "| 6414252|            1|\n",
      "| 9637768|            1|\n",
      "| 9947836|            2|\n",
      "| 9430366|            1|\n",
      "| 7974574|            1|\n",
      "| 5907325|            1|\n",
      "|13749425|            1|\n",
      "| 5771331|            1|\n",
      "| 9784206|            1|\n",
      "| 4702135|            1|\n",
      "|19239110|            1|\n",
      "+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Group the DataFrame by 'host_id' (assuming it uniquely identifies a host)\n",
    "grouped_df = airbnb.groupBy(\"host_id\")\n",
    "\n",
    "# Calculate the total number of reviews for each host using 'count'\n",
    "total_reviews_per_host = grouped_df.agg(count(\"number_of_reviews\").alias(\"total_reviews\"))\n",
    "\n",
    "# Display the results\n",
    "total_reviews_per_host.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Show the min and max of all the numeric variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------+-----------------+---------+-----------+\n",
      "|summary|price|minimum_nights|number_of_reviews| latitude|  longitude|\n",
      "+-------+-----+--------------+-----------------+---------+-----------+\n",
      "|    min|  -74|             0|                0|-74.16254|  -74.24442|\n",
      "|    max|10000|          1250|              629| 40.91306|2.4906404E7|\n",
      "+-------+-----+--------------+-----------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, min, max\n",
    "\n",
    "# Filter numeric columns (assuming you know the column names)\n",
    "numeric_cols = [\"price\", \"minimum_nights\", \"number_of_reviews\", \"latitude\", \"longitude\"]  # Replace with actual column names\n",
    "numeric_df = airbnb.select(numeric_cols)\n",
    "min_max_df = numeric_df.summary('min', 'max')\n",
    "\n",
    "# Calculate min and max for each numeric column\n",
    "\n",
    "\n",
    "# Display the results in a single row\n",
    "min_max_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which host had the highest number of reviews?\n",
    "\n",
    "Only display the top result.\n",
    "\n",
    "Bonus: format the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The host name with the highest number of reviews is: Dona\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "sorted_number_of_reviews = airbnb.orderBy(desc(airbnb[\"number_of_reviews\"]))\n",
    "highest_num_of_reviews = sorted_number_of_reviews.first()\n",
    "print(f'The host name with the highest number of reviews is: {highest_num_of_reviews[\"host_name\"]}')\n",
    "\n",
    "\n",
    "# Listing with the lowest price per night"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. On average, how many nights did most hosts specify for a minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|avg_min_nights|\n",
      "+--------------+\n",
      "|           2.0|\n",
      "+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "# Group the DataFrame by 'host_id' (assuming it uniquely identifies a host)\n",
    "grouped_df = airbnb.groupBy(\"host_id\")\n",
    "\n",
    "# Calculate the average minimum nights per host\n",
    "avg_min_nights_per_host = grouped_df.agg(avg(\"minimum_nights\").alias(\"avg_min_nights\"))\n",
    "\n",
    "# Display only the average value (assuming you're interested in the overall average)\n",
    "avg_min_nights_per_host.select(\"avg_min_nights\").show(1)  # Show only the first row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What is the most expensive neighborhood to stay in on average?\n",
    "\n",
    "Note: only show the one result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive neighbourhood is: Fort Wadsworth\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg, round\n",
    "\n",
    "# Group the DataFrame by 'neighbourhood'\n",
    "grouped_df = airbnb.groupBy(\"neighbourhood\")\n",
    "\n",
    "# Calculate the average price per listing (round to 2 decimal places for better readability)\n",
    "avg_price_per_listing = grouped_df.agg(round(avg(\"price\"), 2).alias(\"avg_price\"))\n",
    "\n",
    "# Sort by average price in descending order and get the first row (most expensive)\n",
    "most_expensive_neighbourhood = avg_price_per_listing.orderBy(\"avg_price\", ascending=False).first()\n",
    "\n",
    "# Display the result (neighbourhood and average price)\n",
    "print(f\"The most expensive neighbourhood is: {most_expensive_neighbourhood.neighbourhood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Display a two by two table that shows the average prices by room type (private and shared only) and neighborhood group (Manhattan and Brooklyn only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+--------+---------+\n",
      "|room_type_neighbourhood_group|Brooklyn|Manhattan|\n",
      "+-----------------------------+--------+---------+\n",
      "|                  Shared room|       1|        1|\n",
      "|                 Private room|       1|        1|\n",
      "+-----------------------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg, round\n",
    "\n",
    "# Filter for private and shared room types (replace with actual names if different)\n",
    "filtered_df = airbnb.filter(col(\"room_type\").isin([\"Private room\", \"Shared room\"]))\n",
    "\n",
    "# Filter for Manhattan and Brooklyn only (replace with actual names if different)\n",
    "filtered_df = filtered_df.filter(\n",
    "    col(\"neighbourhood_group\").isin([\"Manhattan\", \"Brooklyn\"])\n",
    ")\n",
    "\n",
    "# Group by room type and neighbourhood group\n",
    "grouped_df = filtered_df.groupBy([\"room_type\", \"neighbourhood_group\"])\n",
    "\n",
    "# Calculate average price per listing (round to 2 decimal places)\n",
    "avg_price_per_listing = grouped_df.agg(round(avg(\"price\"), 2).alias(\"avg_price\"))\n",
    "\n",
    "# Display as a two-by-two table using PySpark SQL functions (assuming you have a way to display the results as a table)\n",
    "avg_price_per_listing.crosstab(\"room_type\", \"neighbourhood_group\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alright that's all folks!\n",
    "\n",
    "### Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
